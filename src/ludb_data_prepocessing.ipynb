{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T21:23:07.510571Z",
     "start_time": "2023-11-13T21:23:07.501802Z"
    }
   },
   "outputs": [],
   "source": [
    "import wfdb    \n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "record = wfdb.rdrecord('10', pn_dir='ludb/1.0.1/data/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:23:08.168638Z",
     "start_time": "2023-11-13T21:23:07.507575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T21:23:08.175124Z",
     "start_time": "2023-11-13T21:23:08.170111Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(ecg_signal, sampling_rate):\n",
    "\n",
    "    # Bandpass\n",
    "    low = 0.5 / (0.5 * sampling_rate)\n",
    "    high = 20 / (0.5 * sampling_rate)\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    filtered_ecg = filtfilt(b, a, ecg_signal)\n",
    "    mean = np.mean(filtered_ecg)\n",
    "    std = np.std(filtered_ecg)\n",
    "    standardized_data = (filtered_ecg - mean) / std\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data_dir = 'ludb/1.0.1/data/'\n",
    "data_path = '../lobachevsky-university-electrocardiography-database-1.0.1/data/'\n",
    "fs = 500\n",
    "\n",
    "# Get all records\n",
    "records = [f.split('.')[0] for f in os.listdir(data_path) if f.endswith('.dat')]\n",
    "records = sorted(records)\n",
    "\n",
    "# Read the ludb rhythm data\n",
    "ludb_df = pd.read_csv('../lobachevsky-university-electrocardiography-database-1.0.1/ludb.csv', header=None)\n",
    "\n",
    "# Create a dictionary to map record names to their rhythms\n",
    "record_to_rhythm = {row[0]: row[3] for index, row in ludb_df.iterrows()}\n",
    "\n",
    "\n",
    "#print(df[0][0])\n",
    "\n",
    "dfs = []  # List to store individual dataframes\n",
    "\n",
    "\n",
    "for i, record_name in enumerate(records):\n",
    "    # Read the ECG record\n",
    "    record = wfdb.rdrecord(record_name, pn_dir=data_dir)\n",
    "    # Ensure signal is long enough to be trimmed\n",
    "    #if record.p_signal.shape[0] >= 5000:  # Assuming the signals are at least 5000 samples long\n",
    "    # Trim the signal to 3000 samples in length by removing the first 1000 and last 1000 samples\n",
    "    trimmed_signal = record.p_signal[1000:-1000]\n",
    "\n",
    "    # Convert the trimmed signal for lead ii to a DataFrame\n",
    "    lead_i_idx = record.sig_name.index('ii')\n",
    "    df_signals = pd.DataFrame({'ii': normalize(trimmed_signal[:, lead_i_idx], fs)})\n",
    "\n",
    "\n",
    "    # Read the annotations for lead ii\n",
    "    annotations = wfdb.rdann(record_name, 'ii', pn_dir=data_dir)\n",
    "\n",
    "    # Filter annotations to include only those that fall within the trimmed range\n",
    "    valid_annotations = [(index-1000, symbol) for index, symbol in zip(annotations.sample, annotations.symbol)\n",
    "                            if 1000 <= index < record.p_signal.shape[0]-1000]\n",
    "\n",
    "    # Create a column for the lead ii annotations and fill with 0\n",
    "    df_signals['target'] = 0\n",
    "\n",
    "    # Initialize flags for the presence of annotations 'N', 'p', 't'\n",
    "    has_N, has_p, has_t = False, False, False\n",
    "\n",
    "    # Apply valid annotations to the DataFrame\n",
    "    for index, symbol in valid_annotations:\n",
    "        if symbol == 'N':\n",
    "            df_signals.at[index, 'target'] = 2\n",
    "            has_N = True\n",
    "        elif symbol == 'p':\n",
    "            df_signals.at[index, 'target'] = 1\n",
    "            has_p = True\n",
    "        elif symbol == 't':\n",
    "            df_signals.at[index, 'target'] = 3\n",
    "            has_t = True\n",
    "\n",
    "    # Check if all three annotations are present\n",
    "    if has_N and has_p and has_t:\n",
    "        # Add a column to identify the record\n",
    "        df_signals.insert(0, 'record', record_name)\n",
    "\n",
    "\n",
    "        # Retrieve the rhythm for the current record and add it as a new column\n",
    "        rhythm = record_to_rhythm.get(record_name, 'Unknown')\n",
    "        df_signals['rhythm'] = rhythm\n",
    "\n",
    "        # Append this DataFrame to the list\n",
    "        dfs.append(df_signals)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_filtered = pd.concat(dfs, ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:25:32.628721Z",
     "start_time": "2023-11-13T21:23:08.179607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T21:25:33.196749Z",
     "start_time": "2023-11-13T21:25:32.630791Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered.to_csv('ludb_lead_ii_data.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
